{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fundamentals of Unsupervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br /><br />\n",
    "\n",
    "### Motivation\n",
    "\n",
    "So far we have studied algorithms that work with labeled/annotated data and we divided those algorithms in two classes: Regression algorithms - data label is continuous variable; Classification algorithms - data label is discrete/categorical variable. The part of Machine Learning that deals with these kind of algorithms requiring labeled data points is called <b>Supervised Machine Learning</b>.\n",
    "\n",
    "However, there are bunch of cases where data labels are not available! Moreover, most of the data in real world doesn't come with labels! Our goal is to still extract some insights out of these datasets without hiring people to do manual annotation which might be expensive or sometimes impossible. The part of machine learning dealing with unlabeled data is called <b>Unsupervised Machine Learning</b>.\n",
    "\n",
    "Many people believe that unsupervised learning is the key to the general Artificial Intelligence as human babes do most of the learning without explicit supervision.\n",
    "\n",
    "The goal of today's class is to introduce to some of the most popular unsupervised learning algorithms and go through some use-cases where these algorithms are applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Learning Objectives\n",
    "\n",
    "At the end of this class, listeners will be able to:\n",
    "\n",
    "<ul>\n",
    "    <li>Understand conceptual differences between Supervised and Unsupervised machine learning.</li>\n",
    "    <li>Get familiar with several essential unsupervised learning algorithms.</li>\n",
    "    <li>Get intuition about when these algorithms shall be used.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reading Material\n",
    "\n",
    "<ul>\n",
    "    <li>K-Means algorithm: https://youtu.be/J0A_tkIgutw?list=PLnZuxOufsXnvftwTB1HL6mel1V32w0ThI <b>(mandatory)</b></li> \n",
    "    <li>Gaussian Mixture Models: https://youtu.be/I9dfOMAhsug?list=PLnZuxOufsXnvftwTB1HL6mel1V32w0ThI <b>(mandatory)</b></li>\n",
    "    <li>EM algorithm for Gaussian Mixture Models: https://youtu.be/lMShR1vjbUo?list=PLnZuxOufsXnvftwTB1HL6mel1V32w0ThI</li>\n",
    "    <li>DBSCAN algorithm: https://en.wikipedia.org/wiki/DBSCAN</li>\n",
    "    <li>AMLD 2020 workshop material on unsupervised fraud detection: https://github.com/amld/workshop-unsupervised-fraud</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<br /><br /><br /><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is one of the most important and essential sub-topics of unsupervised machine learning that deals with algorithms that separate/cluster data into logical groups without requiring any labeling as we said.  \n",
    "  \n",
    "Below example compares unsupervised ml (namely, clustering algorithm) vs supervised ml."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://assets.extrahop.com/images/blogart/supervised-vs-unsupervised-ml.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering\n",
    "\n",
    "The simplest clustering algorithm is K-means clustering, that separates groups of similar data points by <b>circles</b> as depicted in above picture.  \n",
    "\n",
    "For details of the algorithm refer reading material in top section (~20 minute video).\n",
    "  \n",
    "<br /><br />  \n",
    "  \n",
    "<b>Pros:</b>  \n",
    "\n",
    "<ul><li>Very simple and intuitive</li></ul>\n",
    "\n",
    "<b>Cons:</b>  \n",
    "\n",
    "<ul><li>Non-circular cluster shapes are hard to deal with.</li>\n",
    "    <li>Number of clusters should be set manually, wrong number can result in poor results.</li>\n",
    "    <li>Can get stuck in local minima (solution is to re-run several times and select best one).</li>\n",
    "    <li>Exhibits poor performance in high-dimensional data due to \"curse of dimensionality\". Running dimensionality reduction algorithms (refer below) in advance is usually beneficial.</li>\n",
    "</ul>\n",
    "\n",
    "One of the use-cases of the K-means can be vector-quantization (information compression): https://towardsdatascience.com/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Models (GMMs) for Density Estimation and Clustering\n",
    "\n",
    "Gaussian Mixture Models is a powerful unsupervised learning technique that is used: 1) for clustering; 2) Density Estimation - learning the distribution of the data in order to be able to sample/generate new data points from it. The latter application is most important use-case of GMM in practice.\n",
    "\n",
    "For in-depth details of the algorithm refer reading material in top section.\n",
    "\n",
    "<br /><br /><br />\n",
    "\n",
    "<img src=\"images/unsupervised_ml/gmm.png\" />\n",
    "  \n",
    "<b>Pros:</b>  \n",
    "\n",
    "<ul>\n",
    "    <li>If the number of clusters is large enough, can learn practically any density.</li>\n",
    "    <li>Good Probabilistic Interpretation</li>\n",
    "</ul>\n",
    "\n",
    "<b>Cons:</b>  \n",
    "\n",
    "<ul>\n",
    "    <li>Number of clusters should be set manually, wrong number can result in poor results.</li>\n",
    "    <li>Can get stuck in local minima (solution is to re-run several times and select best one).</li>\n",
    "    <li>Exhibits poor performance in high-dimensional data due to \"curse of dimensionality\". Running dimensionality reduction algorithms (refer below) in advance is usually beneficial.</li>\n",
    "</ul>\n",
    "\n",
    "One of the practical use cases apart from clustering is <b>Anomaly/Outlier Detection</b>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "164px",
    "width": "514px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
