{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create anaconda environment\n",
    "<br>\n",
    "```bash\n",
    "conda create -n ml python=3.7.5 jupyter\n",
    "```\n",
    "Install fastai library\n",
    "<br>\n",
    "```bash\n",
    "conda install -c pytorch -c fastai fastai\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The universal approximation theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a href=\"https://en.wikipedia.org/wiki/Universal_approximation_theorem\">The Universal Approximation Theorem</a>\n",
    "<br>\n",
    "<a href=\"https://www.youtube.com/watch?v=Ijqkc7OLenI\">The Universal Approximation Theorem for neural networks</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Universal approximation theorem says that every compact / mesurable function can be approximated at the any $\\epsilon$ distance with three layer (shallow) wide enough neural network\n",
    "<br>\n",
    "Or with the multilayer fixed width neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/ua_1.jpg\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's images the one dimensional case\n",
    "<img src=\"images/add1/ua_wd_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(0, 1, 0.01)\n",
    "f = lambda x: x**2 + 1\n",
    "y = f(x)\n",
    "x, y, len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def sgm(x:np.ndarray):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "s_1 = np.arange(-4.0, 4.0, 0.1)\n",
    "s = sgm(s_1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(s_1, s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x_1 = np.arange(0, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_h = 1* sgm(1000 * x_1 -300)\n",
    "plt.plot(x_1, y_h)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_h = 1* sgm(1000 * x_1 -300) + -1* sgm(1000 * x_1 - 500)\n",
    "plt.plot(x_1, y_h)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_h = 1* sgm(1000 * x_1 -300) + -1* sgm(1000 * x_1 - 500) + 2 * sgm(1000 * x_1 -500) - 1* sgm(1000 * x_1 - 700)\n",
    "plt.plot(x_1, y_h)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_h = 1* sgm(1000 * x_1 -300) + -1* sgm(1000 * x_1 - 500) + 2 * sgm(1000 * x_1 -500) - 1* sgm(1000 * x_1 - 700) \\\n",
    "+ 3 * sgm(1000 * x_1 -700)\n",
    "plt.plot(x_1, y_h)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_h = 1* sgm(1000 * x_1 -300) + -1* sgm(1000 * x_1 - 500) + 2 * sgm(1000 * x_1 -500) - 1* sgm(1000 * x_1 - 700) \\\n",
    "+ 3 * sgm(1000 * x_1 -700) - 1* sgm(1000 * x_1 - 800)\n",
    "plt.plot(x_1, y_h)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "More approximation need wider layer\n",
    "<img src=\"images/add1/ua_2.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Multi-dimensional examples\n",
    "<img src=\"images/add1/ua_3.jpg\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For better approximation the wider model is needed $\\epsilon \\to 0$ then $n \\to \\infty$ where $n$ is hidden neurons $(h_i)^n_{i=1}$ neurons in hidden layer\n",
    "<img src=\"images/add1/ua_wd_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Multi-layer example:\n",
    "<img src=\"images/add1/ua_4.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/ua_5.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Imagine functions defined on the same domain and let's say similar enough:\n",
    "<img src=\"images/add1/tl_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"burk\">\n",
    "<img src=\"images/add1/tl_2.png\" height=\"800\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/tl_3.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/tl_4.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/tl_5.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/tl_6.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Generalize for more than last layer training at the end\n",
    "- Fine-tune earlier layers, but slightly, with discriminative learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The first layers are representation layers\n",
    "<br>\n",
    "Better representation needed for just training last layers or fine-tuning on smaller amount of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Multi-layer example:\n",
    "<img src=\"images/add1/tl_ml_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/tl_7.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/tl_8.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Turns out that ImageNet pre-training for classification was one of the best pretext task for:\n",
    "- Classification\n",
    "- Object detection\n",
    "- Semantic segmentation\n",
    "- Instance segmentation\n",
    "- RL\n",
    "- Key-point detection\n",
    "- etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Self-supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Labeling data is expensive:\n",
    "- Labeling images for classification\n",
    "- Tend to be biased and has an errors\n",
    "- ImageNet is one of the\n",
    "- Labeling images for detection and segmentation is at least twice expensive and biased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Self supervised learning is ML learning when labels are simple generated by the modification of original data, without human-in-the loop:\n",
    "- Generative models:\n",
    " - Auto-encoders when labels are the original images\n",
    "- Discriminative models:\n",
    " - When labels are the meta information about original data modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Self-supervised representation learning is a self-supervised learning, when model is trained for pretext task and for downstream task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Representation learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Deep models for feature extraction.\n",
    "<br>\n",
    "Train deep model on modified data (pretext task)\n",
    "<br>\n",
    "Use it without last layers as feature extractors and train other model on top of it (downstream task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predicting neighbouring context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/nc_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word embeddings with dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/we_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word embeddings (Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/wv_2.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/wv_3.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/wv_4.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Noise contrastive estimation, instead of softmax on the huge amount of negative samples, we create binary classifier, if pair of vectors are from the same class (yes, no)\n",
    "<br>\n",
    "In our case the same class means then, pair of vectors are from the same image, with different augmentation (or augmentation and source images), or part of the same image\n",
    "<br>\n",
    "All other images or patches can be considered as images from the different classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contrastive learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Imagine two normalized vectors $v_1 = \\frac{z_1}{||z_1||}$ and $v_2 = \\frac{z_2}{||z_2||}$\n",
    "<br>\n",
    "\n",
    "Lets compute scalar product $v_1 \\cdot v_2 = ||v_1|| \\cdot ||v_2|| \\cdot \\cos{(v_1, v_2)}$\n",
    "<br>\n",
    "\n",
    "Because they are normalized, we can imagine that $||v_1|| \\cdot ||v_2|| \\approx 1$ and therefore only $cos(v_1, v_2)$ matters\n",
    "<br>\n",
    "\n",
    "Recall that $\\cos{90^{\\circ}} = 0$ and $\\cos{0^{\\circ}} = 1$\n",
    "<br>\n",
    "\n",
    "So higher cosine means that angle is sharper and therefore (recall that vectors are normalized) vectors are closer to each other:\n",
    "\n",
    "$$\n",
    "v_1 \\cdot v_2 \\text{ is higher } \\implies v_1 \\text{is closer to } v_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/sim_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Geometric and algorithmic perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/nce_det_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/nce_det_2.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/nce_det_3.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mutual-information perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Mutual information maximization between anchor / source and positive examples:\n",
    "$$\n",
    "I(x; c) = \\sum_{x, c}{p(x, c)\\log{\\frac{p(x| c)}{p(x)}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The mutual information:\n",
    "$$\n",
    "I(x; c) = \\sum_{x, c}{\\log{\\frac{p(x, c)}{p(x) \\cdot p(c)}}}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "The joint probability:\n",
    "$$\n",
    "p(x, c) = p(x|c)p(c)\n",
    "$$\n",
    "<br>\n",
    "So we have the above formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"We do not predict future observations $x_{t+k}$ directly with a generative model $p_k(x_{t+k}|c_t)$\"\n",
    "<br>\n",
    "\n",
    "\"Instead we model a density ratio which preserves the mutual information between $x_{t+k}$ and $c_t$\"\n",
    "<br>\n",
    "\n",
    "Instead of predicting future according the past, increase mutual information for future and past in comparison with past and some, random \"negative\" future\n",
    "\n",
    "$$\n",
    "f_k(x_{t+k}, c_t) \\propto \\frac{p(x_{t+k}|c_t)}{p(x_{t+k})}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "This means that we need to make $f_k(x_{t+k}, c_t)$ \"larger\" in order to increase mutual information and make other $f_k(x_{s}, c_t)$ smaller for negative samples $x_s$ and $c_t$ in order to decrease the mutual information between them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The $f_k(x_{t+k}, c_t) = v_{t+k} \\cdot v_t$ can be vector multiplication, as we saw above, which makes vectors closer with higher mutual information and far with less mutual information\n",
    "<br>\n",
    "\n",
    "We can also have more complicated models such as a linear combination:\n",
    "$$\n",
    "f_k(x_{t+k}, c_t) = \\exp(z^T_{t+k} \\cdot W_k \\cdot c_t)\n",
    "$$\n",
    "<br>\n",
    "\n",
    "Or even a neural network instead of $z^T_{t+k} \\cdot W_k \\cdot c_t$ for combination\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-entropy perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\"Cross-entropy is a measure of the difference between two probability distributions for a given random variable or set of events\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The cross entropy of the distribution \n",
    "$q$\n",
    " relative to a distribution \n",
    "$p$\n",
    " over a given set is defined as follows:\n",
    "\n",
    "$$\n",
    "H(p,q)=-{E} _{p}[\\log q]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or for the discrete cases:\n",
    "$$\n",
    "H(p,q)=- \\sum_{x \\in \\mathcal{X}}p(x) \\cdot \\log q(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "On our case $p(x) = 1$ when samples are from the same class\n",
    "<br>\n",
    "So we had to minimize:\n",
    "$$\n",
    "H(p,q)=- \\log q(x)\n",
    "$$\n",
    "<br>\n",
    "for the positive $x$\n",
    "<br>\n",
    "Or in maximize the:\n",
    "$$\n",
    "q(x)\n",
    "$$\n",
    "Note that here $\\mathcal{X} = \\{(x_p, x) \\in \\{x_p\\} \\times X\\}$ and $X = \\{a_k(x) : x \\in X_o, a \\in A\\}$ where $A$ is the set of the augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or in maximize the:\n",
    "$$\n",
    "q(x) = \\frac{f(x_p)}{\\sum{f(x) \\in \\mathcal{X}}}\n",
    "$$\n",
    "where $x_p$ is our positive example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But $f(x_p) = f(x_a, x_p)$ and $f(x) = f(x_p, x)$ all the other examples:\n",
    "$$\n",
    "H(p, q) = \\frac{f(x_a, x_p)}{\\sum_{x \\in X}{f(x_1, x)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Instead of all the negatives $\\sum_{x \\in X}$ we can take \"big enough\" amount of negative samples $X_0 \\subset X$ and $x_a, x_p \\in X_0$:\n",
    "$$\n",
    "H(p, q) = \\frac{f(x_a, x_p)}{\\sum_{x \\in X_0}{f(x_1, x)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contrastive predicting coding (CPC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc1_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc1_4.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc1_6.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc1_9.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/info_nce_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc1_10.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc1_11.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc1_12.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CPC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc2_10.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc2_12.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc2_13.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc2_14.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc2_15.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc2_16.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc2_17.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/cpc2_18.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Instance discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/id_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/id_2.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Momentum contrast (MoCo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/moco1_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/moco1_2.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Initialize model $f_q$ and make a copy - $f_k$, and fixed size queue $L$\n",
    "<br>\n",
    "than take image $x$ and two augmentation functions $a_q$ and $a_k$ (dynamically for each iteration)\n",
    "<br>\n",
    "Augment the source image:\n",
    "$$\n",
    "x_q = a_q(x)\n",
    "$$\n",
    "<br>\n",
    "and\n",
    "$$\n",
    "x_k = a_k(x)\n",
    "$$\n",
    "Calculate representation vectors\n",
    "$$\n",
    "q = f_q(x_q)\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "k = f_k(x_k)\n",
    "$$\n",
    "<br>\n",
    "Calculate the cost:\n",
    "$$\n",
    "c = \\frac{f(q, k)}{\\sum_{l \\in L}f(q, l)}\n",
    "$$\n",
    "<br>\n",
    "Backpropagate only $f_q$ (so the weights W_q are updated)\n",
    "<br>\n",
    "Update $f_k$ models weighs $W_k$ with exponential moving average:\n",
    "$$\n",
    "W_k = \\alpha \\cdot W_k + (1 - \\alpha) \\cdot W_q\n",
    "$$\n",
    "<br>\n",
    "and save representation $k$ in the queue $L = (l_1, l_2, \\dots, l_n)$ (remove oldest and thus less influenced by the $f_q$ models weighs vectors)\n",
    "$$\n",
    "k \\to l_1, \\\\\n",
    "l_1 \\to l_2 \\\\\n",
    "\\cdots \\\\\n",
    "l_{n-1} \\to l_n \\\\\n",
    "$$\n",
    "and $l_n$ goes out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So in queue\n",
    "$$\n",
    "L = (l_1, l_2, \\dots, l_n)\n",
    "$$\n",
    "are representation vectors generated by the $f_k$\n",
    "<br>\n",
    "\n",
    "Lower the index $i$ is, $l_i$ is updated with $f_k = f(x, W_k)$ with closer weights with $f_q = f_q(x, W_q)$ which was updated by the backpropagation\n",
    "<br>\n",
    "\n",
    "The less influenced vectors from the last updated $f_q = f_q(x, W_q)$ is $l_n$ which is removed and queue is updated after each iteration\n",
    "<br>\n",
    "\n",
    "In this manner algorithm maintains the \"better\" representation vectors for negative sampling\n",
    "<br>\n",
    "\n",
    "In my opinion this works plus because $k = f_k(x_k)$ in positive sampling is also calculated with $f_k = f_k(x, W_k)$ which weights was updated in previous iteration with exponentially moving (closest) average of $f_q = f_q(x, W_q)$ model\n",
    "<br>\n",
    "\n",
    "Closest to backpropagated weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now translate everything in batches:\n",
    "<br>\n",
    "Just consider each call as batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/moco1_3.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/moco1_4.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/moco1_5.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/add1/moco1_6.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions\n",
    "\n",
    "<img src=\"images/add1/questions_1.jpg\" height=\"600\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thank you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
